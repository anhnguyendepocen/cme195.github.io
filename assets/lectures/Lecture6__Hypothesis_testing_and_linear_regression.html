<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="dcterms.date" content="2017-10-19" />
  <title>Lecture 6: Hypothesis testing and Linear Regression</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/reveal.css"/>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="libs/reveal.js-3.3.0.1/css/theme/simple.css" id="theme">


  <!-- some tweaks to reveal css -->
  <style type="text/css">
    .reveal h1 { font-size: 2.0em; }
    .reveal h2 { font-size: 1.5em;  }
    .reveal h3 { font-size: 1.25em;	}
    .reveal h4 { font-size: 1em;	}

    .reveal .slides>section,
    .reveal .slides>section>section {
      padding: 0px 0px;
    }



    .reveal table {
      border-width: 1px;
      border-spacing: 2px;
      border-style: dotted;
      border-color: gray;
      border-collapse: collapse;
      font-size: 0.7em;
    }

    .reveal table th {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      font-weight: bold;
      border-style: dotted;
      border-color: gray;
    }

    .reveal table td {
      border-width: 1px;
      padding-left: 10px;
      padding-right: 25px;
      border-style: dotted;
      border-color: gray;
    }


  </style>

    <style type="text/css">code{white-space: pre;}</style>

    <link rel="stylesheet" href="cme195.css"/>

<!-- Printing and PDF exports -->
<script id="paper-css" type="application/dynamic-css">

/* Default Print Stylesheet Template
   by Rob Glazebrook of CSSnewbie.com
   Last Updated: June 4, 2008

   Feel free (nay, compelled) to edit, append, and
   manipulate this file as you see fit. */


@media print {

	/* SECTION 1: Set default width, margin, float, and
	   background. This prevents elements from extending
	   beyond the edge of the printed page, and prevents
	   unnecessary background images from printing */
	html {
		background: #fff;
		width: auto;
		height: auto;
		overflow: visible;
	}
	body {
		background: #fff;
		font-size: 20pt;
		width: auto;
		height: auto;
		border: 0;
		margin: 0 5%;
		padding: 0;
		overflow: visible;
		float: none !important;
	}

	/* SECTION 2: Remove any elements not needed in print.
	   This would include navigation, ads, sidebars, etc. */
	.nestedarrow,
	.controls,
	.fork-reveal,
	.share-reveal,
	.state-background,
	.reveal .progress,
	.reveal .backgrounds {
		display: none !important;
	}

	/* SECTION 3: Set body font face, size, and color.
	   Consider using a serif font for readability. */
	body, p, td, li, div {
		font-size: 20pt!important;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		color: #000;
	}

	/* SECTION 4: Set heading font face, sizes, and color.
	   Differentiate your headings from your body text.
	   Perhaps use a large sans-serif for distinction. */
	h1,h2,h3,h4,h5,h6 {
		color: #000!important;
		height: auto;
		line-height: normal;
		font-family: Georgia, "Times New Roman", Times, serif !important;
		text-shadow: 0 0 0 #000 !important;
		text-align: left;
		letter-spacing: normal;
	}
	/* Need to reduce the size of the fonts for printing */
	h1 { font-size: 28pt !important;  }
	h2 { font-size: 24pt !important; }
	h3 { font-size: 22pt !important; }
	h4 { font-size: 22pt !important; font-variant: small-caps; }
	h5 { font-size: 21pt !important; }
	h6 { font-size: 20pt !important; font-style: italic; }

	/* SECTION 5: Make hyperlinks more usable.
	   Ensure links are underlined, and consider appending
	   the URL to the end of the link for usability. */
	a:link,
	a:visited {
		color: #000 !important;
		font-weight: bold;
		text-decoration: underline;
	}
	/*
	.reveal a:link:after,
	.reveal a:visited:after {
		content: " (" attr(href) ") ";
		color: #222 !important;
		font-size: 90%;
	}
	*/


	/* SECTION 6: more reveal.js specific additions by @skypanther */
	ul, ol, div, p {
		visibility: visible;
		position: static;
		width: auto;
		height: auto;
		display: block;
		overflow: visible;
		margin: 0;
		text-align: left !important;
	}
	.reveal pre,
	.reveal table {
		margin-left: 0;
		margin-right: 0;
	}
	.reveal pre code {
		padding: 20px;
		border: 1px solid #ddd;
	}
	.reveal blockquote {
		margin: 20px 0;
	}
	.reveal .slides {
		position: static !important;
		width: auto !important;
		height: auto !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 0 !important;
		zoom: 1 !important;

		overflow: visible !important;
		display: block !important;

		text-align: left !important;
		-webkit-perspective: none;
		   -moz-perspective: none;
		    -ms-perspective: none;
		        perspective: none;

		-webkit-perspective-origin: 50% 50%;
		   -moz-perspective-origin: 50% 50%;
		    -ms-perspective-origin: 50% 50%;
		        perspective-origin: 50% 50%;
	}
	.reveal .slides section {
		visibility: visible !important;
		position: static !important;
		width: auto !important;
		height: auto !important;
		display: block !important;
		overflow: visible !important;

		left: 0 !important;
		top: 0 !important;
		margin-left: 0 !important;
		margin-top: 0 !important;
		padding: 60px 20px !important;
		z-index: auto !important;

		opacity: 1 !important;

		page-break-after: always !important;

		-webkit-transform-style: flat !important;
		   -moz-transform-style: flat !important;
		    -ms-transform-style: flat !important;
		        transform-style: flat !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;

		-webkit-transition: none !important;
		   -moz-transition: none !important;
		    -ms-transition: none !important;
		        transition: none !important;
	}
	.reveal .slides section.stack {
		padding: 0 !important;
	}
	.reveal section:last-of-type {
		page-break-after: avoid !important;
	}
	.reveal section .fragment {
		opacity: 1 !important;
		visibility: visible !important;

		-webkit-transform: none !important;
		   -moz-transform: none !important;
		    -ms-transform: none !important;
		        transform: none !important;
	}
	.reveal section img {
		display: block;
		margin: 15px 0px;
		background: rgba(255,255,255,1);
		border: 1px solid #666;
		box-shadow: none;
	}

	.reveal section small {
		font-size: 0.8em;
	}

}  
</script>


<script id="pdf-css" type="application/dynamic-css">
    
/**
 * This stylesheet is used to print reveal.js
 * presentations to PDF.
 *
 * https://github.com/hakimel/reveal.js#pdf-export
 */

* {
	-webkit-print-color-adjust: exact;
}

body {
	margin: 0 auto !important;
	border: 0;
	padding: 0;
	float: none !important;
	overflow: visible;
}

html {
	width: 100%;
	height: 100%;
	overflow: visible;
}

/* Remove any elements not needed in print. */
.nestedarrow,
.reveal .controls,
.reveal .progress,
.reveal .playback,
.reveal.overview,
.fork-reveal,
.share-reveal,
.state-background {
	display: none !important;
}

h1, h2, h3, h4, h5, h6 {
	text-shadow: 0 0 0 #000 !important;
}

.reveal pre code {
	overflow: hidden !important;
	font-family: Courier, 'Courier New', monospace !important;
}

ul, ol, div, p {
	visibility: visible;
	position: static;
	width: auto;
	height: auto;
	display: block;
	overflow: visible;
	margin: auto;
}
.reveal {
	width: auto !important;
	height: auto !important;
	overflow: hidden !important;
}
.reveal .slides {
	position: static;
	width: 100%;
	height: auto;

	left: auto;
	top: auto;
	margin: 0 !important;
	padding: 0 !important;

	overflow: visible;
	display: block;

	-webkit-perspective: none;
	   -moz-perspective: none;
	    -ms-perspective: none;
	        perspective: none;

	-webkit-perspective-origin: 50% 50%; /* there isn't a none/auto value but 50-50 is the default */
	   -moz-perspective-origin: 50% 50%;
	    -ms-perspective-origin: 50% 50%;
	        perspective-origin: 50% 50%;
}

.reveal .slides section {
	page-break-after: always !important;

	visibility: visible !important;
	position: relative !important;
	display: block !important;
	position: relative !important;

	margin: 0 !important;
	padding: 0 !important;
	box-sizing: border-box !important;
	min-height: 1px;

	opacity: 1 !important;

	-webkit-transform-style: flat !important;
	   -moz-transform-style: flat !important;
	    -ms-transform-style: flat !important;
	        transform-style: flat !important;

	-webkit-transform: none !important;
	   -moz-transform: none !important;
	    -ms-transform: none !important;
	        transform: none !important;
}

.reveal section.stack {
	margin: 0 !important;
	padding: 0 !important;
	page-break-after: avoid !important;
	height: auto !important;
	min-height: auto !important;
}

.reveal img {
	box-shadow: none;
}

.reveal .roll {
	overflow: visible;
	line-height: 1em;
}

/* Slide backgrounds are placed inside of their slide when exporting to PDF */
.reveal section .slide-background {
	display: block !important;
	position: absolute;
	top: 0;
	left: 0;
	width: 100%;
	z-index: -1;
}

/* All elements should be above the slide-background */
.reveal section>* {
	position: relative;
	z-index: 1;
}

/* Display slide speaker notes when 'showNotes' is enabled */
.reveal .speaker-notes-pdf {
	display: block;
	width: 100%;
	max-height: none;
	left: auto;
	top: auto;
	z-index: 100;
}

/* Display slide numbers when 'slideNumber' is enabled */
.reveal .slide-number-pdf {
	display: block;
	position: absolute;
	font-size: 14px;
}

</script>


<script>
var style = document.createElement( 'style' );
style.type = 'text/css';
var style_script_id = window.location.search.match( /print-pdf/gi ) ? 'pdf-css' : 'paper-css';
var style_script = document.getElementById(style_script_id).text;
style.innerHTML = style_script;
document.getElementsByTagName('head')[0].appendChild(style);
</script>

</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">Lecture 6: Hypothesis testing and Linear Regression</h1>
    <h3 class="date">October 19, 2017</h3>
</section>

<section id="relevant-books" class="slide level2">
<h1>Relevant Books</h1>
<p>For more background in statistics check out the following books:</p>
<ul>
<li><p><a href="http://www-bcf.usc.edu/~gareth/ISL/getbook.html">“An introduction to Statistical Learning”</a> [ESL] by James, Witten, Hastie and Tibshirani</p></li>
<li><p><a href="http://www.springer.com/gp/book/9780387848570">“Elements of statistical learning”</a> [ISL] by Hastie, Tibshirani and Friedman</p></li>
<li><p><a href="http://www.wiley.com/WileyCDA/WileyTitle/productCd-0470542810.html">“Introduction to Linear Regression Analysis”</a> by Montgomery, Peck, Vinning</p></li>
</ul>
<p></br></p>
<center>
<small> All presented material is under a <a href="https://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>. </small>
</center>
</section>
<section id="when-do-you-need-a-model" class="slide level2">
<h1>When do you need a model?</h1>
<p>When you want to:</p>
<ul>
<li class="fragment">detect patterns in the data,</li>
<li class="fragment">predict outcomes for new observations,</li>
<li class="fragment">assess the significance of a factor on the outcome,</li>
<li class="fragment">perform statistical tests</li>
</ul>
</section>
<section><section id="hypothesis-testing" class="titleslide slide level1"><h1>Hypothesis testing</h1></section><section id="hypothesis-testing-1" class="slide level2">
<h1>Hypothesis testing</h1>
<ul>
<li class="fragment">Is a <strong>significant difference</strong> between two groups of observations?</li>
<li class="fragment">e.g. in medical a study, did the treatment group have better outcomes than a control group?</li>
<li class="fragment">The <strong>hypotheses</strong> can be tested with statistical procedures.</li>
</ul>
</section><section id="students-t-test" class="slide level2">
<h1>Student’s t-test</h1>
<ul>
<li class="fragment">William Gosset (1908), a chemist at <strong>the Guiness brewery</strong>.</li>
<li class="fragment">Published in Biometrika under a <strong>pseudonym Student</strong>.</li>
<li class="fragment">Used to <strong>monitor the quality of stouts</strong>.</li>
<li class="fragment">Now one of the standard/traditional methods to <strong>test the equality of the means of two populations</strong>.</li>
</ul>
</section><section id="dataset" class="slide level2">
<h1>Dataset</h1>
<ul>
<li>A built-in dataset, <code>mtcars</code>, that comes from a 1974 issue of Motor Trends magazine.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">data</span>(<span class="st">&quot;mtcars&quot;</span>)
<span class="kw">head</span>(mtcars)</code></pre></div>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1</code></pre>
<ul>
<li>rows correspond to car models,</li>
<li>column are car attributes: miles per gallon, number of cylinders, displacement, transmission etc.</li>
</ul>
</section><section id="testing-equality-of-mpg" class="slide level2">
<h1>Testing equality of mpg</h1>
<p>Is the fuel efficiency (mpg) the same for the cars with automatic and manual transmission?</p>
<p></br> <strong>Test the null hypothesis:</strong></p>
<p><span class="math display">\[H_0: \text{mean mpg of automatic cars = mean mpg of manual cars}\]</span></p>
</section><section id="section" class="slide level2">
<h1></h1>
<p>Convert the column <code>am</code> (transmission) to a factor:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#  convert am (0 = automatic, 1 = manual) column to a factor</span>
mtcars$am &lt;-<span class="st"> </span><span class="kw">factor</span>(mtcars$am, <span class="dt">levels =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), 
                    <span class="dt">labels =</span> <span class="kw">c</span>(<span class="st">&quot;automatic&quot;</span>, <span class="st">&quot;manual&quot;</span>))
<span class="kw">head</span>(mtcars)</code></pre></div>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs        am gear
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0    manual    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0    manual    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1    manual    4
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1 automatic    3
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0 automatic    3
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1 automatic    3
##                   carb
## Mazda RX4            4
## Mazda RX4 Wag        4
## Datsun 710           1
## Hornet 4 Drive       1
## Hornet Sportabout    2
## Valiant              1</code></pre>
</section><section id="section-1" class="slide level2">
<h1></h1>
<p>First, visualize the data</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(mtcars, <span class="kw">aes</span>(<span class="dt">x =</span> am, <span class="dt">y =</span> mpg)) +<span class="st"> </span><span class="kw">geom_boxplot</span>() +
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Trasmission&quot;</span>) +<span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Fuel efficiency&quot;</span>) +
<span class="st">  </span><span class="kw">geom_jitter</span>(<span class="dt">width =</span> <span class="fl">0.4</span>)</code></pre></div>
<p><img src="Lecture6__Hypothesis_testing_and_linear_regression_files/figure-revealjs/unnamed-chunk-3-1.png" width="384" /></p>
</section><section id="section-2" class="slide level2">
<h1></h1>
<p>The R implementation of the Student’s t-test is <code>t.test()</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(tt &lt;-<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">formula =</span> mpg ~<span class="st"> </span>am, <span class="dt">data =</span> mtcars))</code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  mpg by am
## t = -3.7671, df = 18.332, p-value = 0.001374
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -11.280194  -3.209684
## sample estimates:
## mean in group automatic    mean in group manual 
##                17.14737                24.39231</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># or</span>
tt &lt;-<span class="st"> </span><span class="kw">t.test</span>(<span class="dt">x =</span> mtcars$mpg[mtcars$am ==<span class="st"> &quot;automatic&quot;</span>], 
             <span class="dt">y =</span> mtcars$mpg[mtcars$am ==<span class="st"> &quot;manual&quot;</span>])</code></pre></div>
<ul>
<li><strong>A tilde symbol, <code>~</code></strong>, means “explained by”.</li>
<li><code>t.test()</code> outputs group means, the t-statistic and the p-value.</li>
</ul>
</section><section id="p-value" class="slide level2">
<h1>p-value</h1>
<ul>
<li>p-value is the <strong>probability of obtaining a result equal to or “more extreme” than what was actually observed, when the null hypothesis is true</strong>.</li>
<li>A small p-value (typically <span class="math inline">\(\le 0.05\)</span>) indicates strong evidence against the null hypothesis, so you reject the null hypothesis.</li>
<li>A large p-value (&gt; 0.05) indicates weak evidence against the null hypothesis, so you do NOT to reject the null hypothesis.</li>
</ul>
</section><section id="distribution-of-the-statistic" class="slide level2">
<h1>Distribution of the statistic</h1>
<p><img src="Lecture6__Hypothesis_testing_and_linear_regression_files/figure-revealjs/unnamed-chunk-5-1.png" width="576" /></p>
</section><section id="section-3" class="slide level2">
<h1></h1>
<p>Here, the p-value is equal to <span class="math inline">\(\mathbb{P}[| \bar X_{aut} - \bar X_{man}| \ge d\; | \; | H_0] = \mathbb{P}[| \bar X_{aut} - \bar X_{man}| \ge d \; | \; |\mu_{aut} - \mu_{man}| = 0]\)</span> where <span class="math inline">\(d\)</span> is the difference observed in your samples.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Remember tt &lt;- t.test(formula = mpg ~ am, data = mtcars)</span>
<span class="kw">names</span>(tt)</code></pre></div>
<pre><code>## [1] &quot;statistic&quot;   &quot;parameter&quot;   &quot;p.value&quot;     &quot;conf.int&quot;    &quot;estimate&quot;   
## [6] &quot;null.value&quot;  &quot;alternative&quot; &quot;method&quot;      &quot;data.name&quot;</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The p-value:</span>
tt$p.value</code></pre></div>
<pre><code>## [1] 0.001373638</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># The 95% confidence interval for the difference between the two means:</span>
tt$conf.int</code></pre></div>
<pre><code>## [1] -11.280194  -3.209684
## attr(,&quot;conf.level&quot;)
## [1] 0.95</code></pre>
</section></section>
<section><section id="supervised-learning" class="titleslide slide level1"><h1>Supervised Learning</h1></section><section id="supervised-learning-1" class="slide level2">
<h1>Supervised Learning</h1>
<ul>
<li><p><strong>Supervised Learning</strong> is a task of inferring the relationship between the input data and the response variable, <span class="math inline">\(y = f(x)\)</span>.</p></li>
<li><p>In supervised learning each observation consist of a pair <span class="math inline">\((x, y)\)</span> where <span class="math inline">\(x\)</span> is the input data, e.g. a collection of the attributes, and <span class="math inline">\(y\)</span> the label or the output value.</p></li>
<li><p>Supervised learning problems can be divided into:</p>
<ul>
<li><p><strong>Regression</strong>: <span class="math inline">\(y\)</span> is a <em>quantitative</em> variable (numerical/continuous/ordered) e.g. mileage per gallon in the <code>mtcars</code> dataset</p></li>
<li><p><strong>Classification</strong>: <span class="math inline">\(y\)</span> is a <em>qualitative</em> variable (categorical)<br />
e.g. transmission in the <code>mtcars</code> dataset</p></li>
</ul></li>
</ul>
</section></section>
<section><section id="linear-regression" class="titleslide slide level1"><h1>Linear Regression</h1></section><section id="linear-regression-1" class="slide level2">
<h1>Linear Regression</h1>
<ul>
<li class="fragment"><strong>Linear regression</strong> is a type of regression where the quantitative output variable is modeled as a <strong>linear</strong> function of the inputs.</li>
</ul>
<ul>
<li class="fragment"><strong>Simple linear regression</strong> predicts the output <span class="math inline">\(y\)</span> from a single predictor <span class="math inline">\(x\)</span>. That is we assume the outcome <span class="math inline">\(y\)</span> follows the following linear model, where <span class="math inline">\(\epsilon\)</span> is a random noise term with zero mean. <span class="math display">\[y = \beta_0 + \beta_1 x + \epsilon\]</span></li>
</ul>
<ul>
<li class="fragment"><strong>Multiple linear regression</strong> assumes <span class="math inline">\(y\)</span> relies on many covariates: <span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_p x_p + \epsilon =
\vec \beta \vec x + \epsilon\]</span></li>
</ul>
</section><section id="objective-function" class="slide level2">
<h1>Objective function</h1>
<p>Linear regression seeks a solution <span class="math inline">\(\hat y = \hat \beta \cdot \vec x\)</span> that minimizes the difference between the true outcome <span class="math inline">\(y\)</span> and the prediction <span class="math inline">\(\hat y\)</span>, in terms of the residual sum of squares (RSS).</p>
<p><span class="math display">\[arg \min\limits_{\hat \beta} \sum_i \left(y^{(i)} - \hat \beta x^{(i)}\right)^2\]</span></p>
</section><section id="simple-linear-regression" class="slide level2">
<h1>Simple Linear Regression</h1>
<ul>
<li><p>Predict the mileage per gallon using the weight of the car.</p></li>
<li><p>In R the linear models can be fit with a <code>lm</code> function.</p></li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg ~<span class="st"> </span>wt, mtcars)</code></pre></div>
<ul>
<li>Same formula as for the <code>t.test</code> function.</li>
</ul>
</section><section id="section-4" class="slide level2">
<h1></h1>
<p>We can check the details on the fitted model by calling:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5432 -2.3647 -0.1252  1.4096  6.8727 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  37.2851     1.8776  19.858  &lt; 2e-16 ***
## wt           -5.3445     0.5591  -9.559 1.29e-10 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 3.046 on 30 degrees of freedom
## Multiple R-squared:  0.7528, Adjusted R-squared:  0.7446 
## F-statistic: 91.38 on 1 and 30 DF,  p-value: 1.294e-10</code></pre>
</section><section id="section-5" class="slide level2">
<h1></h1>
<p>The coefficients (<span class="math inline">\(\beta\)</span>) of the model can be extracted with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(co &lt;-<span class="st">  </span><span class="kw">coef</span>(<span class="kw">summary</span>(fit)))</code></pre></div>
<pre><code>##              Estimate Std. Error   t value     Pr(&gt;|t|)
## (Intercept) 37.285126   1.877627 19.857575 8.241799e-19
## wt          -5.344472   0.559101 -9.559044 1.293959e-10</code></pre>
<p><span class="math inline">\(\hat y\)</span> = predicted <code>mpg</code> values for existing observations (cars)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(fit)[<span class="dv">1</span>:<span class="dv">15</span>]</code></pre></div>
<pre><code>##          Mazda RX4      Mazda RX4 Wag         Datsun 710 
##           23.28261           21.91977           24.88595 
##     Hornet 4 Drive  Hornet Sportabout            Valiant 
##           20.10265           18.90014           18.79325 
##         Duster 360          Merc 240D           Merc 230 
##           18.20536           20.23626           20.45004 
##           Merc 280          Merc 280C         Merc 450SE 
##           18.90014           18.90014           15.53313 
##         Merc 450SL        Merc 450SLC Cadillac Fleetwood 
##           17.35025           17.08302            9.22665</code></pre>
</section><section id="section-6" class="slide level2">
<h1></h1>
<p>To predict the <code>mpg</code> for the <strong>new observations</strong>, cars with specific weights, e.g. <code>wt = 3.14</code> we can use the computed coefficients:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">co[, <span class="dv">1</span>]</code></pre></div>
<pre><code>## (Intercept)          wt 
##   37.285126   -5.344472</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># beta0 + beta1 * wt</span>
co[<span class="dv">1</span>, <span class="dv">1</span>] +<span class="st"> </span>co[<span class="dv">2</span>, <span class="dv">1</span>]*<span class="st"> </span><span class="fl">3.14</span> <span class="co">#  37.285126 +  (-5.344472) * 3.14</span></code></pre></div>
<pre><code>## [1] 20.50349</code></pre>
<p>Predictions for a number of new observations:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># create a data frame with new weights:</span>
newcars &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">wt =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="fl">2.1</span>, <span class="fl">3.14</span>, <span class="fl">4.1</span>, <span class="fl">4.3</span>))
<span class="co"># Note the same prediction for `wt = 3.14` as computed previously.</span>
<span class="kw">predict</span>(fit, newcars)</code></pre></div>
<pre><code>##        1        2        3        4        5 
## 26.59618 26.06174 20.50349 15.37279 14.30390</code></pre>
</section><section id="section-7" class="slide level2">
<h1></h1>
<p><code>ggplot2</code> can plot the data and the fitted model without having to compute the <code>lm</code> model ahead. <code>geom_smoother</code> with the <code>method</code> argument set to <code>&quot;lm&quot;</code> does the computations automatically.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(mtcars, <span class="kw">aes</span>(wt, mpg)) +<span class="st"> </span><span class="kw">geom_point</span>() +<span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>)</code></pre></div>
<p><img src="Lecture6__Hypothesis_testing_and_linear_regression_files/figure-revealjs/unnamed-chunk-15-1.png" width="960" /></p>
</section><section id="multiple-linear-regression" class="slide level2">
<h1>Multiple Linear Regression</h1>
<ul>
<li>Can be fitted using the same function <code>lm()</code>.</li>
<li>Predict <code>mpg</code> using weight, displacement and the number of cylinders in the car.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(mtcars, <span class="kw">aes</span>(<span class="dt">x=</span>wt, <span class="dt">y=</span>mpg, <span class="dt">col=</span>cyl, <span class="dt">size=</span>disp)) +<span class="st"> </span><span class="kw">geom_point</span>()</code></pre></div>
<p><img src="Lecture6__Hypothesis_testing_and_linear_regression_files/figure-revealjs/unnamed-chunk-16-1.png" width="960" /></p>
</section><section id="section-8" class="slide level2">
<h1></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mfit &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg ~<span class="st"> </span>wt +<span class="st"> </span>disp +<span class="st"> </span>cyl, <span class="dt">data =</span> mtcars)

<span class="co"># Summarize the results </span>
<span class="kw">summary</span>(mfit)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ wt + disp + cyl, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.4035 -1.4028 -0.4955  1.3387  6.0722 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 41.107678   2.842426  14.462 1.62e-14 ***
## wt          -3.635677   1.040138  -3.495  0.00160 ** 
## disp         0.007473   0.011845   0.631  0.53322    
## cyl         -1.784944   0.607110  -2.940  0.00651 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.595 on 28 degrees of freedom
## Multiple R-squared:  0.8326, Adjusted R-squared:  0.8147 
## F-statistic: 46.42 on 3 and 28 DF,  p-value: 5.399e-11</code></pre>
</section><section id="no-intercept-model" class="slide level2">
<h1>No intercept model</h1>
<p>You can choose the fix the intercept at 0 with:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mfit0 &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg ~<span class="st"> </span><span class="dv">0</span> +<span class="st"> </span>wt +<span class="st"> </span>disp +<span class="st"> </span>cyl, <span class="dt">data =</span> mtcars)

<span class="co"># Summarize the results </span>
<span class="kw">summary</span>(mfit0)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ 0 + wt + disp + cyl, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -10.530  -4.147   1.219   6.516  14.641 
## 
## Coefficients:
##      Estimate Std. Error t value Pr(&gt;|t|)    
## wt    6.12494    2.26328   2.706  0.01128 *  
## disp -0.12830    0.02065  -6.213  8.9e-07 ***
## cyl   4.67349    1.17614   3.974  0.00043 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 7.42 on 29 degrees of freedom
## Multiple R-squared:  0.8863, Adjusted R-squared:  0.8745 
## F-statistic: 75.36 on 3 and 29 DF,  p-value: 8.468e-14</code></pre>
</section><section id="section-9" class="slide level2">
<h1></h1>
<p>To <strong>predict <code>mpg</code> for new cars</strong>, you must first create a data frame describing the attributes of the new cars:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(newcars &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">wt =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="fl">2.1</span>, <span class="fl">3.14</span>, <span class="fl">4.1</span>, <span class="fl">4.3</span>),
                      <span class="dt">disp =</span> <span class="kw">c</span>(<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">500</span>,<span class="dv">300</span>, <span class="dv">210</span>),
                      <span class="dt">cyl =</span> <span class="kw">c</span>(<span class="dv">6</span>,<span class="dv">6</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>)))</code></pre></div>
<pre><code>##     wt disp cyl
## 1 2.00  100   6
## 2 2.10  200   6
## 3 3.14  500   4
## 4 4.10  300   6
## 5 4.30  210   8</code></pre>
<p>Then you can compute the predicted <code>mpg</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(mfit, newcars)</code></pre></div>
<pre><code>##        1        2        3        4        5 
## 23.87395 24.25768 26.28834 17.73362 12.76403</code></pre>
</section><section id="interaction-terms" class="slide level2">
<h1>Interaction terms</h1>
<ul>
<li><p><strong>An interaction</strong> occurs when an independent variable has a different effect on the outcome depending on the values of another independent variable.</p></li>
<li><p>If you are not familiar with the concept of the interaction terms, read <a href="http://www.medicine.mcgill.ca/epidemiology/joseph/courses/EPIB-621/interaction.pdf">this</a>.</p></li>
</ul>
</section><section id="section-10" class="slide level2">
<h1></h1>
<p>Models with <strong>interaction effects</strong> can be specified with ’*’:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mfit_iter &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg ~<span class="st"> </span>am *<span class="st"> </span>wt, mtcars)
<span class="kw">summary</span>(mfit_iter)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ am * wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6004 -1.5446 -0.5325  0.9012  6.0909 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  31.4161     3.0201  10.402 4.00e-11 ***
## ammanual     14.8784     4.2640   3.489  0.00162 ** 
## wt           -3.7859     0.7856  -4.819 4.55e-05 ***
## ammanual:wt  -5.2984     1.4447  -3.667  0.00102 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.591 on 28 degrees of freedom
## Multiple R-squared:  0.833,  Adjusted R-squared:  0.8151 
## F-statistic: 46.57 on 3 and 28 DF,  p-value: 5.209e-11</code></pre>
</section><section id="interaction-terms-1" class="slide level2">
<h1>Interaction terms</h1>
<p>Note that ’*’ generates all the terms:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(<span class="kw">coefficients</span>(mfit_iter))</code></pre></div>
<pre><code>## [1] &quot;(Intercept)&quot; &quot;ammanual&quot;    &quot;wt&quot;          &quot;ammanual:wt&quot;</code></pre>
<p>You can also specify explicitly which terms you want:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mfit_iter2 &lt;-<span class="st"> </span><span class="kw">lm</span>(mpg ~<span class="st"> </span><span class="dv">1</span> +<span class="st"> </span>am +<span class="st"> </span>wt +<span class="st"> </span>am:wt, mtcars)
<span class="kw">summary</span>(mfit_iter2)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = mpg ~ 1 + am + wt + am:wt, data = mtcars)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.6004 -1.5446 -0.5325  0.9012  6.0909 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  31.4161     3.0201  10.402 4.00e-11 ***
## ammanual     14.8784     4.2640   3.489  0.00162 ** 
## wt           -3.7859     0.7856  -4.819 4.55e-05 ***
## ammanual:wt  -5.2984     1.4447  -3.667  0.00102 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.591 on 28 degrees of freedom
## Multiple R-squared:  0.833,  Adjusted R-squared:  0.8151 
## F-statistic: 46.57 on 3 and 28 DF,  p-value: 5.209e-11</code></pre>
</section></section>
<section><section id="lasso-regression" class="titleslide slide level1"><h1>Lasso Regression</h1></section><section id="choosing-a-model" class="slide level2">
<h1>Choosing a model</h1>
<ul>
<li>Modern datasets often have “too” many variables, e.g. predict the risk of a disease from the single nucleotide polymorphisms (SNPs) data.</li>
<li><strong>Issue:</strong> <span class="math inline">\(n \ll p\)</span> i.e. no. of predictors is much larger than than the no. of observations.</li>
<li><strong>Lasso regression</strong> is especially useful for problems, where</li>
</ul>
<blockquote>
<p>the number of available covariates is extremely large, but only a handful of them are relevant for the prediction of the outcome.</p>
</blockquote>
</section><section id="lasso-regression-1" class="slide level2">
<h1>Lasso Regression</h1>
<ul>
<li>Lasso regression is simply regression with <span class="math inline">\(L_1\)</span> penalty.</li>
<li>That is, it solves the problem:</li>
</ul>
<p><span class="math display">\[\hat \beta ^*  = arg \min\limits_{\hat \beta} \sum_i \left(y^{(i)} 
- \hat \beta x^{(i)}\right)^2 + \lambda \|\hat \beta\|_1\]</span></p>
<ul>
<li><p>It turns out that the <span class="math inline">\(L_1\)</span> norm <span class="math inline">\(\|\vec x\|_1 = \sum_j |x_j|\)</span> <strong>promotes sparsity</strong>.</p></li>
<li><p>The solution, <span class="math inline">\(\hat \beta^*\)</span>, usually has only a small number of non-zero coefficients.</p></li>
<li><p>The number of non-zero coefficients depends on the choice of the tuning parameter, <span class="math inline">\(\lambda\)</span>. The higher the <span class="math inline">\(\lambda\)</span> the fewer non-zero coefficients.</p></li>
</ul>
</section><section id="glmnet" class="slide level2">
<h1><code>glmnet</code></h1>
<ul>
<li>Lasso regression is implemented in an R package <code>glmnet</code>.</li>
<li>An introductory tutorial to the package can be found <a href="https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html">here</a>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;glmnet&quot;)</span>
<span class="kw">library</span>(glmnet)</code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## Loading required package: foreach</code></pre>
<pre><code>## Loaded glmnet 2.0-13</code></pre>
</section><section id="section-11" class="slide level2">
<h1></h1>
<ul>
<li>We go back to <code>mtcars</code> datasets and use Lasso regression to predict the <code>mpg</code> using all variables.</li>
<li>Lasso will pick a subset of predictors (the ones with non-zero coefficents) that best predict the <code>mpg</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mtcars)</code></pre></div>
<pre><code>##                    mpg cyl disp  hp drat    wt  qsec vs        am gear
## Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0    manual    4
## Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0    manual    4
## Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1    manual    4
## Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1 automatic    3
## Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0 automatic    3
## Valiant           18.1   6  225 105 2.76 3.460 20.22  1 automatic    3
##                   carb
## Mazda RX4            4
## Mazda RX4 Wag        4
## Datsun 710           1
## Hornet 4 Drive       1
## Hornet Sportabout    2
## Valiant              1</code></pre>
</section><section id="section-12" class="slide level2">
<h1></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y &lt;-<span class="st"> </span>mtcars[, <span class="dv">1</span>]  <span class="co"># mileage per gallon </span>
x &lt;-<span class="st"> </span>mtcars[, -<span class="dv">1</span>] <span class="co"># all other variables treated as predictors</span>
x &lt;-<span class="st"> </span><span class="kw">data.matrix</span>(x, <span class="st">&quot;matrix&quot;</span>) <span class="co"># converts to NUMERIC matrix</span>
<span class="co"># Choose a training set</span>
<span class="kw">set.seed</span>(<span class="dv">123</span>)
trainIdx &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(mtcars), <span class="kw">round</span>(<span class="fl">0.7</span> *<span class="st"> </span><span class="kw">nrow</span>(mtcars)))
fit &lt;-<span class="st"> </span><span class="kw">glmnet</span>(x[trainIdx, ], y[trainIdx])
<span class="kw">names</span>(fit)</code></pre></div>
<pre><code>##  [1] &quot;a0&quot;        &quot;beta&quot;      &quot;df&quot;        &quot;dim&quot;       &quot;lambda&quot;   
##  [6] &quot;dev.ratio&quot; &quot;nulldev&quot;   &quot;npasses&quot;   &quot;jerr&quot;      &quot;offset&quot;   
## [11] &quot;call&quot;      &quot;nobs&quot;</code></pre>
</section><section id="section-13" class="slide level2">
<h1></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(fit)</code></pre></div>
<pre><code>## 
## Call:  glmnet(x = x[trainIdx, ], y = y[trainIdx]) 
## 
##       Df   %Dev   Lambda
##  [1,]  0 0.0000 4.679000
##  [2,]  1 0.1383 4.264000
##  [3,]  2 0.2626 3.885000
##  [4,]  2 0.3700 3.540000
##  [5,]  2 0.4593 3.225000
##  [6,]  2 0.5333 2.939000
##  [7,]  2 0.5948 2.678000
##  [8,]  2 0.6459 2.440000
##  [9,]  2 0.6883 2.223000
## [10,]  2 0.7235 2.026000
## [11,]  2 0.7527 1.846000
## [12,]  2 0.7770 1.682000
## [13,]  3 0.7993 1.532000
## [14,]  3 0.8179 1.396000
## [15,]  3 0.8335 1.272000
## [16,]  3 0.8463 1.159000
## [17,]  3 0.8570 1.056000
## [18,]  3 0.8659 0.962300
## [19,]  3 0.8733 0.876800
## [20,]  4 0.8797 0.798900
## [21,]  4 0.8862 0.727900
## [22,]  4 0.8915 0.663300
## [23,]  4 0.8960 0.604300
## [24,]  4 0.8997 0.550700
## [25,]  4 0.9028 0.501700
## [26,]  4 0.9054 0.457200
## [27,]  4 0.9075 0.416600
## [28,]  4 0.9093 0.379500
## [29,]  5 0.9108 0.345800
## [30,]  6 0.9124 0.315100
## [31,]  5 0.9139 0.287100
## [32,]  5 0.9152 0.261600
## [33,]  5 0.9162 0.238400
## [34,]  5 0.9171 0.217200
## [35,]  5 0.9178 0.197900
## [36,]  5 0.9184 0.180300
## [37,]  5 0.9189 0.164300
## [38,]  5 0.9193 0.149700
## [39,]  4 0.9197 0.136400
## [40,]  4 0.9199 0.124300
## [41,]  4 0.9201 0.113200
## [42,]  4 0.9203 0.103200
## [43,]  5 0.9215 0.094020
## [44,]  7 0.9263 0.085660
## [45,]  7 0.9313 0.078050
## [46,]  6 0.9350 0.071120
## [47,]  6 0.9361 0.064800
## [48,]  6 0.9371 0.059050
## [49,]  7 0.9379 0.053800
## [50,]  7 0.9387 0.049020
## [51,]  8 0.9396 0.044670
## [52,]  9 0.9414 0.040700
## [53,] 10 0.9443 0.037080
## [54,] 10 0.9473 0.033790
## [55,] 10 0.9499 0.030790
## [56,] 10 0.9520 0.028050
## [57,] 10 0.9538 0.025560
## [58,] 10 0.9553 0.023290
## [59,] 10 0.9565 0.021220
## [60,] 10 0.9575 0.019330
## [61,] 10 0.9584 0.017620
## [62,] 10 0.9591 0.016050
## [63,] 10 0.9597 0.014630
## [64,] 10 0.9602 0.013330
## [65,] 10 0.9606 0.012140
## [66,] 10 0.9609 0.011060
## [67,] 10 0.9612 0.010080
## [68,] 10 0.9614 0.009186
## [69,] 10 0.9616 0.008369
## [70,] 10 0.9618 0.007626
## [71,] 10 0.9619 0.006949
## [72,] 10 0.9620 0.006331
## [73,] 10 0.9621 0.005769
## [74,] 10 0.9622 0.005256
## [75,] 10 0.9623 0.004789
## [76,] 10 0.9623 0.004364
## [77,] 10 0.9624 0.003976
## [78,] 10 0.9624 0.003623
## [79,] 10 0.9625 0.003301
## [80,] 10 0.9625 0.003008
## [81,] 10 0.9625 0.002741
## [82,] 10 0.9625 0.002497
## [83,] 10 0.9626 0.002275
## [84,] 10 0.9626 0.002073
## [85,] 10 0.9626 0.001889
## [86,] 10 0.9626 0.001721
## [87,] 10 0.9626 0.001568</code></pre>
</section><section id="section-14" class="slide level2">
<h1></h1>
<ul>
<li><code>glmnet()</code> compute the Lasso regression for a sequence of different tuning parameters, <span class="math inline">\(\lambda\)</span>.</li>
<li>Each row of <code>print(fit)</code> corresponds to a particular <span class="math inline">\(\lambda\)</span> in the sequence.</li>
<li>column <code>Df</code> denotes the number of non-zero coefficients (degrees of freedom),</li>
<li><code>%Dev</code> is the percentage variance explained,</li>
<li><code>Lambda</code> is the value of the currently chosen tuning parameter.</li>
</ul>
</section><section id="section-15" class="slide level2">
<h1></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># label = TRUE makes the plot annotate the curves with the corresponding coeffients labels.</span>
<span class="kw">plot</span>(fit, <span class="dt">label =</span> <span class="ot">TRUE</span>) </code></pre></div>
<p><img src="Lecture6__Hypothesis_testing_and_linear_regression_files/figure-revealjs/unnamed-chunk-28-1.png" width="480" /></p>
<ul>
<li>the y-axis corresponds the value of the coefficients.</li>
<li>the x-axis is denoted “<span class="math inline">\(L_1\)</span> norm” but is scaled to indicate the number of non-zero coefficients (the effective degrees of freedom).</li>
</ul>
</section><section id="section-16" class="slide level2">
<h1></h1>
<ul>
<li>Each curve corresponds to a single variable, and shows the value of the coefficient as the tuning parameter varies.</li>
<li><span class="math inline">\(\|\hat \beta\|_{L_1}\)</span> increases and <span class="math inline">\(\lambda\)</span> decreases from left to right.</li>
<li>When <span class="math inline">\(\lambda\)</span> is small (right) there are more non-zero coefficients.</li>
</ul>
<p>The computed Lasso coefficient for a particular choice of <span class="math inline">\(\lambda\)</span> can be printed using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Lambda = 1</span>
<span class="kw">coef</span>(fit, <span class="dt">s =</span> <span class="dv">1</span>)</code></pre></div>
<pre><code>## 11 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                        1
## (Intercept) 34.877093111
## cyl         -0.867649618
## disp         .          
## hp          -0.005778702
## drat         .          
## wt          -2.757808266
## qsec         .          
## vs           .          
## am           .          
## gear         .          
## carb         .</code></pre>
</section><section id="section-17" class="slide level2">
<h1></h1>
<ul>
<li>Like for <code>lm()</code>, we can use a function <code>predict()</code> to predict the <code>mpg</code> for the training or the test data.</li>
<li>However, we need specify the value of <span class="math inline">\(\lambda\)</span> using the argument <code>s</code>.</li>
</ul>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Predict for the test set:</span>
<span class="kw">predict</span>(fit, <span class="dt">newx =</span> x[-trainIdx, ], <span class="dt">s =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">1.5</span>, <span class="dv">2</span>))</code></pre></div>
<pre><code>##                           1        2        3
## Datsun 710         25.36098 23.87240 23.22262
## Valiant            19.82245 19.42427 19.41920
## Duster 360         16.19324 17.27111 17.74858
## Merc 230           22.62471 21.86937 21.50396
## Merc 450SE         15.20595 16.16123 16.71324
## Cadillac Fleetwood 11.25687 13.28117 14.26985
## Chrysler Imperial  10.81730 13.01570 14.07314
## Fiat 128           25.88928 24.20103 23.47110
## Toyota Corolla     27.01880 25.08206 24.22690
## Toyota Corona      24.89106 23.51713 22.92237</code></pre>
<p>Each of the columns corresponds to a choice of <span class="math inline">\(\lambda\)</span>.</p>
</section><section id="choosing-lambda" class="slide level2">
<h1>Choosing <span class="math inline">\(\lambda\)</span></h1>
<ul>
<li>To choose <span class="math inline">\(\lambda\)</span> can use <a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)">cross-validation</a>.</li>
<li>Use <code>cv.glmnet()</code> function to perform a k-fold cross validation.</li>
</ul>
<blockquote>
<p>In k-fold cross-validation, the original sample is randomly partitioned into k equal sized subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k − 1 subsamples are used as training data. <a href="#/fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>
</blockquote>
</section><section id="section-18" class="slide level2">
<h1></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">1</span>)
<span class="co"># `nfolds` argument sets the number of folds (k).</span>
cvfit &lt;-<span class="st"> </span><span class="kw">cv.glmnet</span>(x[trainIdx, ], y[trainIdx], <span class="dt">nfolds =</span> <span class="dv">5</span>)
<span class="kw">plot</span>(cvfit)</code></pre></div>
<p><img src="Lecture6__Hypothesis_testing_and_linear_regression_files/figure-revealjs/unnamed-chunk-31-1.png" width="480" /></p>
<ul>
<li>The <span style="color:red">red dots</span> are the average MSE over the k-folds.</li>
<li>The two chosen <span class="math inline">\(\lambda\)</span> values are the one with <span class="math inline">\(MSE_{min}\)</span> and one with <span class="math inline">\(MSE_{min} + sd_{min}\)</span></li>
</ul>
</section><section id="section-19" class="slide level2">
<h1></h1>
<p><span class="math inline">\(\lambda\)</span> with minimum MSE:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvfit$lambda.min</code></pre></div>
<pre><code>## [1] 0.2171905</code></pre>
<p>The biggest <span class="math inline">\(\lambda\)</span> such that the MSE is within one standard error of the minimum MSE.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cvfit$lambda.1se</code></pre></div>
<pre><code>## [1] 0.6632685</code></pre>
</section></section>
<section><section id="exercise-i" class="titleslide slide level1"><h1>Exercise I</h1></section><section id="exercise-i-1" class="slide level2">
<h1>Exercise I</h1>
<p>In this exercise you will perform Lasso regression yourself. We will use the <code>Boston</code> dataset from the <code>MASS</code> package. The dataset contains information on the Boston suburbs housing market collected by David Harrison in 1978.</p>
<p>We will try to predict the median value of of homes in the region based on its attributes recorded in other variables.</p>
<p>First install the package:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># install.packages(&quot;MASS&quot;)</span>
<span class="kw">library</span>(MASS)</code></pre></div>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:plotly&#39;:
## 
##     select</code></pre>
</section><section id="section-20" class="slide level2">
<h1></h1>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(Boston, <span class="dv">3</span>)</code></pre></div>
<pre><code>##      crim zn indus chas   nox    rm  age    dis rad tax ptratio  black
## 1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90
## 2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90
## 3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83
##   lstat medv
## 1  4.98 24.0
## 2  9.14 21.6
## 3  4.03 34.7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">str</span>(Boston)</code></pre></div>
<pre><code>## &#39;data.frame&#39;:    506 obs. of  14 variables:
##  $ crim   : num  0.00632 0.02731 0.02729 0.03237 0.06905 ...
##  $ zn     : num  18 0 0 0 0 0 12.5 12.5 12.5 12.5 ...
##  $ indus  : num  2.31 7.07 7.07 2.18 2.18 2.18 7.87 7.87 7.87 7.87 ...
##  $ chas   : int  0 0 0 0 0 0 0 0 0 0 ...
##  $ nox    : num  0.538 0.469 0.469 0.458 0.458 0.458 0.524 0.524 0.524 0.524 ...
##  $ rm     : num  6.58 6.42 7.18 7 7.15 ...
##  $ age    : num  65.2 78.9 61.1 45.8 54.2 58.7 66.6 96.1 100 85.9 ...
##  $ dis    : num  4.09 4.97 4.97 6.06 6.06 ...
##  $ rad    : int  1 2 2 3 3 3 5 5 5 5 ...
##  $ tax    : num  296 242 242 222 222 222 311 311 311 311 ...
##  $ ptratio: num  15.3 17.8 17.8 18.7 18.7 18.7 15.2 15.2 15.2 15.2 ...
##  $ black  : num  397 397 393 395 397 ...
##  $ lstat  : num  4.98 9.14 4.03 2.94 5.33 ...
##  $ medv   : num  24 21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 ...</code></pre>
</section><section id="section-21" class="slide level2">
<h1></h1>
<p>Split the data to training and testing subsets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">123</span>)
trainIdx &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">1</span>:<span class="kw">nrow</span>(Boston), <span class="kw">round</span>(<span class="fl">0.7</span> *<span class="st"> </span><span class="kw">nrow</span>(Boston)))
boston.test &lt;-<span class="st"> </span>Boston[-trainIdx,<span class="st">&quot;medv&quot;</span>]</code></pre></div>
<p>Perform a Lasso regression with <code>glmnet</code>. Steps:</p>
<ol type="1">
<li>Extract the input and output data from the <code>Boston</code> <code>data.frame</code> and convert them if necessary to a correct format.</li>
<li>Use cross-validation to select the value for <span class="math inline">\(\lambda\)</span>.</li>
<li>Inspect comuted coefficients for <code>lambda.min</code>.</li>
<li>Compute the predictions for the test dataset the two choices of the tuning parameter, <code>lambda.min</code> and <code>lambda.1se</code>. Evaluate the MSE for each.</li>
</ol>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># (... ?)</span></code></pre></div>
</section></section>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><p><a href="https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation" class="uri">https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation</a><a href="#/fnref1">↩</a></p></li>
</ol>
</section>
    </div>
  </div>

  <script src="libs/reveal.js-3.3.0.1/lib/js/head.min.js"></script>
  <script src="libs/reveal.js-3.3.0.1/js/reveal.js"></script>

  <script>

      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        // Display the page number of the current slide
        slideNumber: true,
        // Push each slide change to the browser history
        history: true,
        // Vertical centering of slides
        center: true,
        // Transition style
        transition: 'slide', // none/fade/slide/convex/concave/zoom
        // Transition style for full page slide backgrounds
        backgroundTransition: 'default', // none/fade/slide/convex/concave/zoom



        // Optional reveal.js plugins
        dependencies: [
        ]
      });
    </script>
  <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
      var script = document.createElement("script");
      script.type = "text/javascript";
      script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
      document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>

<script>
  (function() {
    if (window.jQuery) {
      Reveal.addEventListener( 'slidechanged', function(event) {  
        window.jQuery(event.previousSlide).trigger('hidden');
        window.jQuery(event.currentSlide).trigger('shown');
      });
    }
  })();
</script>


  </body>
</html>
